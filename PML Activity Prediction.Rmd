---
title: "Activity Prediction"
author: "Efremov Victor"
date: "Sunday, July 26, 2015"
output: 
  html_document:
    keep_md: true
---

##Executive Summary

The goal of this work is to predict the manner in which people did the exercise. 
For this, we use  data from accelerometers on the belt, forearm, arm, and 
dumbell from 6 participants. People were asked to perform barbell lifts 
correctly and incorrectly in 5 different ways. 

We build a machine learning algorithm that predicted with high accuracy the 
manner in which the participants did the exercise. Algorithm based on a Random 
Forest model. This algorithm have accuracy 0.989, and correctly predicted all 
test cases.

##Data Processing

###Data loading:

Download the dataset:

```{r cache=TRUE}
# Download dataset
url_training <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
url_test <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(url_training, "pml-training.csv")
download.file(url_test, "pml-testing.csv")

# Read this files
DataTraining <- read.csv(file = "pml-training.csv",
                         head=TRUE,
                         na.strings=c("NA", "", "#DIV/0!"),
                         sep=",")

DataTesting <- read.csv(file = "pml-testing.csv",
                         head=TRUE,
                         na.strings=c("NA", "", "#DIV/0!"),
                         sep=",")
```
###Clear the data:

First, remove some useless variables like names of people and date of 
observations (first 7 columns). Additionally, remove ?classe? column from first 
dataset (in order that it does not influence on the statistics.

```{r cache=TRUE}
DataTestingClear <- DataTesting[,-c(1:7,160)]
DataTrainingClear <- DataTraining[,-c(1:7,160)]
```

If we look at quantity of NA values, we find that some of columns have more than 
19000 NA values. So, remove them.

```{r cache=TRUE}
delCol <- which(colSums(is.na(DataTrainingClear)) > 19000)
DataTrainingClear <- DataTrainingClear[, -c(delCol)]
DataTestingClear <- DataTestingClear[, -c(delCol)]
```

Check predictors that have one unique value: there are no such predictors in clean dataset 

```{r cache=TRUE, echo=FALSE}
library(caret)
```
```{r cache=TRUE}
zeroPred <- nearZeroVar(DataTrainingClear)
```

Then, find predictors with high correlation, and remove them:

```{r cache=TRUE}
library(corrplot)

corVar = cor(DataTrainingClear, method = "spearman")
```
```{r cache=TRUE, fig.width=9, fig.height=9}
# Make square plot of correlation between predictors
corrplot(corVar, method = "square")

```
```{r cache=TRUE}

# Find all predictors with koef.of corellation greater than 0.7 by modulus.
highCor = findCorrelation(corVar, cutoff = 0.7)

# And remove them
DataTestingClear = DataTestingClear[, -highCor]
DataTrainingClear = DataTrainingClear[, -highCor]
```

And restore ```classe``` column into clean dataset

```{r cache=TRUE}
DataTrainingClear$classe = DataTraining$classe
```

###Create Machine Learning Model

```{r cache=TRUE}
set.seed(1937)

# split the dataset into a training and test data.
inTrain <- createDataPartition(y=DataTrainingClear$classe, p=0.7, list=FALSE)
training <- DataTrainingClear [inTrain,] 
testing <- DataTrainingClear [-inTrain,] 

# define training control with 10-fold cross-validation
train_control <- trainControl(method = "cv", 
                              number = 10
                              )

# Build the Random Forest model
model <- train(classe ~ ., 
               data = training, 
               trControl = train_control, 
               method = "rf"
               )
```

##Validate Model

Look at confusion matrix:

```{r cache=TRUE}
pred <- predict(model, testing)

confusionMatrix(pred, testing$classe)
```

##Summary

Overall accuracy is 0.989, and in matrix see only a few isolated cases of 
missed detection if it is not-adjacent classes. So, we believe that the results 
of Random Forest model are good enough for this task, and overall accuracy is 
sufficiently high.

##Making Predictions

So, we may predict the class for the 20 test cases from the test dataset:

```{r cache=TRUE}
answers <- predict(model, DataTesting)

print(answers)
```

**When submitted,  all these predictions were correct.**



*End.*




